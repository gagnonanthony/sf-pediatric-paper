{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027b5ea0",
   "metadata": {},
   "source": [
    "#### **Computing normative models of diffusion metrics for each bundle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de207c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0a57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root Dir for the project.\n",
    "ROOT_DIR = \"/Users/anthonygagnon/Documents/École/Université/Projects/nf-pediatric/\"\n",
    "RESULTS_DIR = ROOT_DIR + \"NormativeModels/\"\n",
    "REPOSITORY = \"/Users/anthonygagnon/code/nf-pediatric-paper/\"\n",
    "\n",
    "# Dataset folder\n",
    "PING_DATA = ROOT_DIR + \"/PING/\"\n",
    "BCP_DATA = ROOT_DIR + \"/BCP/\"\n",
    "BANDA_DATA = ROOT_DIR + \"/BANDA/\"\n",
    "GESTE_DATA = ROOT_DIR + \"/GESTE/\"\n",
    "ABCD_DATA = ROOT_DIR + \"/ABCD/\"\n",
    "MYRNA_DATA = ROOT_DIR + \"/MYRNA/\"\n",
    "\n",
    "# Create a directory for the results if it doesn't exist\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43474090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Harding font.\n",
    "font_files = []\n",
    "for fontpath in font_manager.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
    "    if \"Harding\".lower() in fontpath.lower():\n",
    "        font_files.append(fontpath)\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "# Set Harding font.\n",
    "plt.rcParams['font.family'] = 'Harding Text Web'\n",
    "\n",
    "# Set the Set2 color palette as an iterable.\n",
    "cmap = sns.color_palette(\"Set2\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a544f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with missing demo data from PING dataframe\n",
      "Dropped 839 rows with missing demo data from BCP dataframe\n",
      "Dropped 0 rows with missing demo data from BANDA dataframe\n",
      "Dropped 49 rows with missing demo data from GESTE dataframe\n",
      "Dropped 0 rows with missing demo data from ABCD dataframe\n",
      "Dropped 296 rows with missing demo data from MYRNA dataframe\n"
     ]
    }
   ],
   "source": [
    "# Load the data for each cohort.\n",
    "ping_df = pd.read_csv(PING_DATA + \"bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "ping_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "bcp_df = pd.read_csv(BCP_DATA + \"withPriors/bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "bcp_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "banda_df = pd.read_csv(BANDA_DATA + \"bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "banda_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "geste_df = pd.read_csv(GESTE_DATA + \"bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "geste_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "abcd_df = pd.read_csv(ABCD_DATA + \"bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "abcd_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "myrna_df = pd.read_csv(MYRNA_DATA + \"bundles_mean_stats.tsv\", sep=\"\\t\")\n",
    "myrna_df.rename(columns={\"sample\": \"subject_id\", \"session\": \"session_id\"}, inplace=True)\n",
    "\n",
    "# Fetch demo info.\n",
    "myrna_demo = pd.read_csv(ROOT_DIR + \"/StudyPopulation/MYRNA_demographics.csv\")\n",
    "myrna_demo['session_id'] = [\"\" for _ in range(len(myrna_demo))]\n",
    "myrna_demo.rename(columns={\"subject_id\": \"participant_id\"}, inplace=True)\n",
    "bcp_demo = pd.read_csv(ROOT_DIR + \"/Connectivity/BCPConnectivityMats/participants.tsv\", sep=\"\\t\")\n",
    "bcp_sex = pd.read_csv(ROOT_DIR + \"/StudyPopulation/BCP_demographics.csv\")\n",
    "geste_demo = pd.read_csv(ROOT_DIR + \"/Connectivity/GESTEConnectivityMats/participants.tsv\", sep=\"\\t\")\n",
    "geste_sex = pd.read_csv(ROOT_DIR + \"/StudyPopulation/GESTE_demographics.csv\")\n",
    "abcd_demo = pd.read_csv(ROOT_DIR + \"/Connectivity/ABCDConnectivityMats/participants.tsv\", sep=\"\\t\")\n",
    "banda_demo = pd.read_csv(ROOT_DIR + \"/Connectivity/BANDAConnectivityMats/participants.tsv\", sep=\"\\t\")\n",
    "ping_demo = pd.read_csv(ROOT_DIR + \"/Connectivity/PINGConnectivityMats/participants.tsv\", sep=\"\\t\")\n",
    "ping_demo[\"session_id\"] = [\"\" for _ in range(len(ping_demo))]\n",
    "\n",
    "# Append sex to bcp_demo by iterating over subject id and fetching the sex value in bcp_sex\n",
    "for i, row in bcp_demo.iterrows():\n",
    "    subject_id = row['participant_id']\n",
    "    sex = bcp_sex.loc[bcp_sex['subject_id'] == subject_id, 'sex'].values\n",
    "    if len(sex) > 0:\n",
    "        bcp_demo.at[i, 'sex'] = sex[0]\n",
    "\n",
    "# Same thing for GESTE\n",
    "for i, row in geste_demo.iterrows():\n",
    "    subject_id = row['participant_id']\n",
    "    sex = geste_sex.loc[geste_sex['subject_id'] == subject_id, 'sex'].values\n",
    "    if len(sex) > 0:\n",
    "        geste_demo.at[i, 'sex'] = sex[0]\n",
    "\n",
    "# Reorder all columns in demographics dataframes to have subject_id, session_id, sex, age, and cohort (append cohort if not present)\n",
    "df = [myrna_demo, bcp_demo, geste_demo, abcd_demo, banda_demo, ping_demo]\n",
    "for i in range(len(df)):\n",
    "    if 'cohort' not in df[i].columns:\n",
    "        df[i]['cohort'] = ['MYRNA', 'BCP', 'GESTE', 'ABCD', 'BANDA', 'PING'][i]\n",
    "    cols = ['participant_id', 'session_id', 'sex', 'age', 'cohort']\n",
    "    df[i] = df[i][cols]\n",
    "\n",
    "ping_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "bcp_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "geste_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "abcd_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "banda_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "myrna_demo.rename(columns={\"participant_id\": \"subject_id\"}, inplace=True)\n",
    "\n",
    "# Function that will fetch corresponding demo data for each subject/session in a row.\n",
    "def fetch_demo_data(row, demo_df):\n",
    "    subject_id = row['subject_id']\n",
    "    session_id = row['session_id']\n",
    "    if isinstance(session_id, str) or not np.isnan(session_id):\n",
    "        demo_row = demo_df[(demo_df['subject_id'] == subject_id) & (demo_df['session_id'] == session_id)]\n",
    "    else:\n",
    "        demo_row = demo_df[(demo_df['subject_id'] == subject_id)]\n",
    "    if not demo_row.empty:\n",
    "        return pd.Series({\n",
    "            'age': demo_row.iloc[0]['age'],\n",
    "            'sex': demo_row.iloc[0]['sex'],\n",
    "            'cohort': demo_row.iloc[0]['cohort']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({'age': None, 'sex': None, 'cohort': None})\n",
    "\n",
    "# Use this function to merge demo data into each cohort dataframe.\n",
    "def merge_with_demo(cohort_df, demo_df):\n",
    "    demo_data = cohort_df.apply(lambda row: fetch_demo_data(row, demo_df), axis=1)\n",
    "    merged_df = pd.concat([cohort_df.reset_index(drop=True), demo_data.reset_index(drop=True)], axis=1)\n",
    "    return merged_df\n",
    "\n",
    "ping_df = merge_with_demo(ping_df, ping_demo)\n",
    "bcp_df = merge_with_demo(bcp_df, bcp_demo)\n",
    "banda_df = merge_with_demo(banda_df, banda_demo)\n",
    "geste_df = merge_with_demo(geste_df, geste_demo)\n",
    "abcd_df = merge_with_demo(abcd_df, abcd_demo)\n",
    "myrna_df = merge_with_demo(myrna_df, myrna_demo)\n",
    "\n",
    "# Assert that there is no missing values in sex, age, or cohort columns.\n",
    "for df, name in zip([ping_df, bcp_df, banda_df, geste_df, abcd_df, myrna_df],\n",
    "                    ['PING', 'BCP', 'BANDA', 'GESTE', 'ABCD', 'MYRNA']):\n",
    "    # Let's drop any rows with missing demo data for now.\n",
    "    length_before = len(df)\n",
    "    df.dropna(subset=['age', 'sex', 'cohort'], inplace=True)\n",
    "    length_after = len(df)\n",
    "\n",
    "    print(f\"Dropped {length_before - length_after} rows with missing demo data from {name} dataframe\")\n",
    "\n",
    "    assert df['sex'].notnull().all(), f\"Missing sex values in {name} dataframe\"\n",
    "    assert df['age'].notnull().all(), f\"Missing age values in {name} dataframe\"\n",
    "    assert df['cohort'].notnull().all(), f\"Missing cohort values in {name} dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3992fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61 outliers!\n",
      "Number of subjects before removing outliers: 1496\n",
      "Number of subjects after removing outliers: 1438\n"
     ]
    }
   ],
   "source": [
    "# Do a big sanity check that all dataframes have the same columns\n",
    "dataframes = [ping_df, bcp_df, banda_df, geste_df, abcd_df, myrna_df]\n",
    "first_df_columns = set(dataframes[0].columns)\n",
    "for i, df in enumerate(dataframes[1:], start=1):\n",
    "    if set(df.columns) != first_df_columns:\n",
    "        raise ValueError(f\"DataFrame at index {i} has different columns.\")\n",
    "\n",
    "# Concatenate all dataframes into a single one.\n",
    "all_data_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Now remove outliers based on the 3 IQR rule for each bundle and each metric.\n",
    "outliers = set()\n",
    "metrics = ['fa', 'md', 'rd', 'ad', 'afd_fixel']\n",
    "for bundle in all_data_df['bundle'].unique():\n",
    "    bundle_df = all_data_df[all_data_df['bundle'] == bundle]\n",
    "    for metric in metrics:\n",
    "        median = bundle_df[metric].quantile(0.5)\n",
    "        iqr = bundle_df[metric].quantile(0.75) - bundle_df[metric].quantile(0.25)\n",
    "        lower_bound = median - 5 * iqr\n",
    "        upper_bound = median + 5 * iqr\n",
    "        bundle_outliers = bundle_df[(bundle_df[metric] < lower_bound) | (bundle_df[metric] > upper_bound)]\n",
    "        for _, row in bundle_outliers.iterrows():\n",
    "            outliers.add((row['subject_id'], row['session_id'] if 'session_id' in row else None))\n",
    "\n",
    "# Print out the outliers found.\n",
    "print(f\"Found {len(outliers)} outliers!\")\n",
    "print(\"Number of subjects before removing outliers:\", len(all_data_df['subject_id'].unique()))\n",
    "\n",
    "# Remove outliers from the all_data_df dataframe.\n",
    "for subject_id, session_id in outliers:\n",
    "    if not (pd.isna(session_id) or session_id == \"\"):\n",
    "        all_data_df = all_data_df[~((all_data_df['subject_id'] == subject_id) & (all_data_df['session_id'] == session_id))]\n",
    "    else:\n",
    "        all_data_df = all_data_df[all_data_df['subject_id'] != subject_id]\n",
    "\n",
    "# Print out the number of subjects after removing outliers.\n",
    "print(\"Number of subjects after removing outliers:\", len(all_data_df['subject_id'].unique()))\n",
    "\n",
    "all_data_df.to_csv(RESULTS_DIR + \"all_cohort_bundles_mean_stats.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ea111e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anthonygagnon/code/nf-pediatric-paper/notebooks/../scripts/bundleGAMLSS.py:85: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(args.in_dataframe, sep=\"\\t\")\n",
      "Fitting GAMLSS models for each provided bundle: 100%|█| 32/32 [1:00:11<00:00, 11\n"
     ]
    }
   ],
   "source": [
    "# Fit GAMLSS models for each metric and bundle using R script.\n",
    "!python ../scripts/bundleGAMLSS.py \\\n",
    "    \"{RESULTS_DIR}/all_cohort_bundles_mean_stats.tsv\" \\\n",
    "    \"{RESULTS_DIR}/GAMLSS_Models/\" \\\n",
    "    --metric fa ad md rd \\\n",
    "    --rscript \"{REPOSITORY}/scripts/gamlss.R\" \\\n",
    "    --bundle AF_L AF_R CC_Fr_1 CC_Fr_2 CC_Oc CC_Pa CC_Pr_Po CC_Te CG_L CG_R FAT_L FAT_R FPT_L FPT_R FX_L FX_R IFOF_L IFOF_R ILF_L ILF_R MdLF_L MdLF_R OR_ML_L OR_ML_R POPT_L POPT_R PYT_L PYT_R SLF_L SLF_R UF_L UF_R\\\n",
    "    --n_cpus 6 \\\n",
    "    -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurostatx-0.1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
